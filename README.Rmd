---
output: md_document
---

# Pachyderm Spatial Demo with R steps

## Step 1 - push your image to a container registry 

**If you you have your containers ready in a container registry, go to step 2**

1. Ponemos el service account de ixplaza en la carpeta `demo_espacial` de este repositorio y trabajamos desde esta misma carpeta todos los pasos, este service account vamos asumir que se llama `gcs_ixplaza_key.json`.

2. Una vez en la carpeta `pachyderm_hub`, nos autenticamos por medio de ese service account en google usando :

```
gcloud auth activate-service-account --key-file=gcs_ixplaza_key.json
```

3. Hacemos el built del Dockerfile con:

```
docker build -t gcr.io/ixplaza/espacial .
```

4. Dejamos que docker se autentifique con google para que pueda acceder al container registry. Para ello hacemos:

```
gcloud auth configure-docker
```

5. Hacemos el push al container registry de google con:

```
docker push gcr.io/ixplaza/espacial
```

# Ejecutar Pachyderm

1. Vamos a Pachyderm Hub y creamos un cluster.

2. Lo primero que tenemos que hacer es seguir las instrucciones en la terminal tal cual aparecen en la opción de `connect`. La opción `connect` se muestra en la siguiente imagen:

![](img/1.png)

3. Una vez configurado, podemos usar `pachctl version` y validar que el cluster está funcionando con `pachd`.

4. Vamos a trabajar en la carpeta `pachyderm_hub` así que en la terminal nos dirigimos a esa carpeta.

5. Creamos el repositorio de entrada donde van a estar los shapes. En este caso se va a llamar `shapes`. Lo hacemos con:

```
pachctl create repo shapes_sp
```

Podemos verificar que se creó correctamente con `pachtl list repo`.

6. Para traer los datos desde un bucket externo, en GCP para este caso, se necesita dar los permisos a ese bucket del service account que asigna automáticament Pachyderm. Si ejecutamos el siguiente comando nos dará un error, pero se muestra el service account al que debemos dar acceso en el bucket:

```
pachctl put file shapes_sp@master -r -f gs://pachyderm_demo/shapes/
```

Los permisos que debemos dar, al menos en GCP, son `Storage Object Viewer`. Una vez que damos los permisos volvemos a ejecutar el comando para traer los datos al repositorio de entrada de Pachyderm.

7. Para poder acceder a la imagen que está ahora en el container registry la forma más sencilla que encontramos es hacer público el container registry. Dado que solo tenemos imagenes para esta demo, decidimos hacerlo así por el momento. Una vez que está público entonces Pachyderm puede acceder a esa imagen sin ningún problema.

8. Ponemos a trabajar el primer pipeline con:

```
pachctl create pipeline -f pipeline_split.json
```

9. Para ver los logs de cada corrida podemos usar `pachctl logs --pipeline=separate_shape`, y además podemos ver el avance del trabajo usando `pachctl inspect job <job_id>` en donde el `<job_id>` podemos obtenerlo de `pachctl list job`.

10. Una vez que termina, el archivo `playas.rds` se usará para cada uno de los segmentos, es decir se debe usar en cada datum. La forma de poder hacer esto es mandando el archivo `playas.rds` a un repositorio nuevo y hacer un `cross` en los repositorios de entrada (esto me permite usar más de un repositorio de entrada). Pachyderm combina cada unidad de un repositorio con los del otro de manera que en este caso se tendrá disponible las playas en cada datum de segmento. Para ello vamos a crear un nuevo repositorio llamado `playas` y llevamos aquí el archivo `playas.rds`

```
pachctl create repo playas
pachctl get file separate_shape@master:/shapes_segmentos/playas/playas.rds -o playas.rds
pachctl put file playas@master -f playas.rds
rm playas.rds
```
10. Hecho esto poner a correr el siguiente pipeline. Lo hacemos con:

```
pachctl create pipeline -f pipeline_distances.json
```

Para ver el proceso podemos hacer `pachctl inspect job <id_job>` en donde se puede obtener el `<id_job>` haciendo `pachctl list job` y se copia el `ID` del job que queremos consultar.

11. Por último se debe correr el pipeline que une todos los archivos en uno solo. Esto lo hacemos con:

```
pachctl create pipeline -f pipeline_join.json
```

12. Cuando termina de ejecutarse el pipeline anterior, para sacar el archivo final del repositorio de salida `une_segmentos`, podemos hacer:

```
pachctl get file une_segmentos@master:/segmentos_playas.rds -o <path_al_que_queremos_copiar_archivo/segmentos_playas.rds>
```

13. **IMPORTANTE:** Debemos quitar el acceso y permisos del service account que pusimos en el bucket `pachyderm_demo` en GCP, donde tragimos los datos inciales para el repositorio de entrada `logsdl`.
